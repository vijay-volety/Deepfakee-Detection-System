# CPU-only fallback docker-compose
version: '3.8'

services:
  # Frontend Service
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    ports:
      - "3000:3000"
    environment:
      - REACT_APP_API_URL=http://localhost:8000
      - REACT_APP_INFERENCE_URL=http://localhost:8001
    depends_on:
      - backend
    networks:
      - deepfake-network

  # Backend API Service
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    ports:
      - "8000:8000"
    environment:
      - DATABASE_URL=sqlite:///./deepfake.db
      - JWT_SECRET_KEY=your-secret-key-change-in-production
      - INFERENCE_SERVICE_URL=http://inference:8001
      - REDIS_URL=redis://redis:6379
    volumes:
      - ./backend/app:/app
      - uploads:/app/uploads
    depends_on:
      - redis
    networks:
      - deepfake-network

  # Inference Service (CPU-only)
  inference:
    build:
      context: ./inference
      dockerfile: Dockerfile.cpu
    ports:
      - "8001:8001"
    environment:
      - DEVICE=cpu
      - MODEL_PATH=/models
    volumes:
      - ./models/checkpoints:/models
      - ./inference/models:/app/models
    networks:
      - deepfake-network

  # Redis for task queue
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    networks:
      - deepfake-network

volumes:
  uploads:

networks:
  deepfake-network:
    driver: bridge